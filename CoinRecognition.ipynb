{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liESJ-lZTVe1",
        "outputId": "e2003672-b226-4076-895d-5c3f0df64ee1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "input_path = Path('/content/drive/MyDrive/Dataset')\n",
        "image_files = list(input_path.glob('*.*'))\n",
        "#print(image_files)\n",
        "labels = [image_file.name for image_file in image_files]\n",
        "labels = labels[:-1]\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xp928krUlAK",
        "outputId": "cf2e781f-cd5a-429e-9995-04cb0aa48617"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['50c.jpg', 'R1.jpg', 'R5.jpg', '5-1.jpeg', 'R2.jpg', '5-2.jpeg', '20c.jpg', '5-3.jpeg', '5-4.jpeg', '5-5.jpeg', '5-6.jpeg', '10c.jpg', '10c_O 1.png', '10c_R1.png', 'R1_O 1.png', '20c_R1.png', '20c_O 1.png', 'R1_R1.png', '50c_O1.png', 'R2_O1.png', '50c_R1.png', 'R2_R1.png', 'R5_RA.png', 'R5_O1.png', '.ipynb_checkpoints', '10c_thresholded.jpg', '10c_region_segmented.jpg', '10c_edge_segmented.jpg', 'Felzenszwalb_Segmentation_50c.jpg', 'Felzenszwalb_Segmentation_R1.jpg', 'Felzenszwalb_Segmentation_R5.jpg', 'Felzenszwalb_Segmentation_R2.jpg', 'Felzenszwalb_Segmentation_20c.jpg', 'Felzenszwalb_Segmentation_10c.jpg', 'Felzenszwalb_Segmentation_10c_O 1.png', 'Felzenszwalb_Segmentation_10c_R1.png', 'Felzenszwalb_Segmentation_R1_O 1.png', 'Felzenszwalb_Segmentation_20c_R1.png', 'Felzenszwalb_Segmentation_20c_O 1.png', 'Felzenszwalb_Segmentation_R1_R1.png', 'Felzenszwalb_Segmentation_50c_O1.png', 'Felzenszwalb_Segmentation_R2_O1.png', 'Felzenszwalb_Segmentation_50c_R1.png', 'Felzenszwalb_Segmentation_R2_R1.png', 'Felzenszwalb_Segmentation_R5_RA.png', 'Felzenszwalb_Segmentation_R5_O1.png', 'Felzenszwalb_Segmentation_10c_thresholded.jpg', 'Felzenszwalb_Segmentation_10c_region_segmented.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "\n",
        "# Load the segmented coins image\n",
        "segmented_coins_path = '/content/drive/MyDrive/Dataset/10c.jpg'\n",
        "segmented_coins = cv2.imread(segmented_coins_path)\n",
        "\n",
        "# Convert the segmented coins image to grayscale\n",
        "gray_coins = cv2.cvtColor(segmented_coins, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Color features\n",
        "color_features = segmented_coins.reshape(-1, 3)  # Reshape the image to a 2D array\n",
        "mean_color = color_features.mean(axis=0)  # Calculate the mean color values\n",
        "\n",
        "# Define a lookup table mapping color features to coin values\n",
        "lookup_table = {\n",
        "   # (131, 109, 73): '1 cent',\n",
        "    #(201, 164, 109): '2 cents',\n",
        "  #  (202, 161, 112): '5 cents',\n",
        "    (184, 194, 218): '10 cents',\n",
        "    (183, 197,215): '20 cents',\n",
        "    (186, 201, 217): '50 cents',\n",
        "    (192, 192, 194): '1 rand',\n",
        "    (201, 201, 202): '2 rand',\n",
        "    (193,  202, 211): '5 rand',\n",
        "    (168, 185, 197):'5 rand'\n",
        "}\n",
        "\n",
        "# Find the closest color in the lookup table using Manhattan distance\n",
        "closest_color = min(lookup_table, key=lambda x: np.sum(np.abs(x - mean_color)))\n",
        "\n",
        "# Extract the value label from the lookup table\n",
        "value_label = lookup_table[closest_color]\n",
        "\n",
        "# Shape features\n",
        "contours, _ = cv2.findContours(gray_coins, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "if len(contours) > 0:\n",
        "    coin_contour = max(contours, key=cv2.contourArea)\n",
        "    perimeter = cv2.arcLength(coin_contour, True)\n",
        "else:\n",
        "    perimeter = 0\n",
        "\n",
        "# Texture features\n",
        "glcm = greycomatrix(gray_coins, [1], [0], 256, symmetric=True, normed=True)\n",
        "contrast = greycoprops(glcm, 'contrast')[0][0]\n",
        "dissimilarity = greycoprops(glcm, 'dissimilarity')[0][0]\n",
        "homogeneity = greycoprops(glcm, 'homogeneity')[0][0]\n",
        "energy = greycoprops(glcm, 'energy')[0][0]\n",
        "correlation = greycoprops(glcm, 'correlation')[0][0]\n",
        "\n",
        "# Print the extracted features and value label\n",
        "print('Mean color:', mean_color)\n",
        "print('Perimeter:', perimeter)\n",
        "print('Contrast:', contrast)\n",
        "print('Dissimilarity:', dissimilarity)\n",
        "print('Homogeneity:', homogeneity)\n",
        "print('Energy:', energy)\n",
        "print('Correlation:', correlation)\n",
        "print('Value of coin:', value_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AfQLMSdVqiw",
        "outputId": "67b15f43-0421-4c02-ff17-22f956eca431"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean color: [184.112925 194.5326   218.472525]\n",
            "Perimeter: 796.0\n",
            "Contrast: 924.9878140703518\n",
            "Dissimilarity: 16.337663316582915\n",
            "Homogeneity: 0.3078851168210063\n",
            "Energy: 0.18387263246901808\n",
            "Correlation: 0.8955283766721857\n",
            "Value of coin: 10 cents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skimage/feature/__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
            "  removed_version='1.0')\n",
            "/usr/local/lib/python3.10/dist-packages/skimage/feature/__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
            "  removed_version='1.0')\n",
            "/usr/local/lib/python3.10/dist-packages/skimage/feature/__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
            "  removed_version='1.0')\n",
            "/usr/local/lib/python3.10/dist-packages/skimage/feature/__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
            "  removed_version='1.0')\n",
            "/usr/local/lib/python3.10/dist-packages/skimage/feature/__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
            "  removed_version='1.0')\n",
            "/usr/local/lib/python3.10/dist-packages/skimage/feature/__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
            "  removed_version='1.0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Prepare the dataset\n",
        "X = []\n",
        "y = []\n",
        "# Specify the directory path where the coin dataset is located\n",
        "dataset_dir = '/content/drive/MyDrive/Dataset/'\n",
        "\n",
        "\n",
        "# Define the label mapping\n",
        "label_mapping = {\n",
        "    '10c.jpg': '10 cents',\n",
        "    '20c.jpg': '20 cents',\n",
        "    '50c.jpg': '50 cents',\n",
        "    'R1.jpg': '1 rand',\n",
        "    'R2.jpg': '2 rand',\n",
        "    'R5.jpg': '5 rand',\n",
        "    '10c_O 1.png':'10 cents',\n",
        "    '10c_R1.png':'10 cents',\n",
        "    '20c_O 1.png':'20 cents',\n",
        "    '20c_R1.png':'20 cents',\n",
        "    '5-1.jpeg': '5 rand',\n",
        "    '5-2.jpeg':'5 rand',\n",
        "    '5-3.jpeg':'5 rand',\n",
        "    '5-4.jpeg':'5 rand',\n",
        "    '5-5.jpeg':'5 rand',\n",
        "    '5-6.jpeg':'5 rand',\n",
        "    '50c_O1.png':'50 cents',\n",
        "    '50c_R1.png':'50 cents',\n",
        "    'R1_O 1.png':'1 rand',\n",
        "    'R1_R1.png':'1 rand',\n",
        "    'R2_O1.png':'2 rand',\n",
        "    'R2_R1.png':'2 rand',\n",
        "    'R5_O1.png':'5 rand',\n",
        "    'R5_RA.png':'5 rand',\n",
        "    'Felzenszwalb_Segmentation_10c.jpg': '10 cents',\n",
        "    'Felzenszwalb_Segmentation_10c_O 1.png': '10 cents',\n",
        "    'Felzenszwalb_Segmentation_10c_R1.png': '10 cents',\n",
        "    'Felzenszwalb_Segmentation_10c_edge_segmented.jpg':'10 cents',\n",
        "    'Felzenszwalb_Segmentation_10c_region_segmented.jpg':'10 cents',\n",
        "    'Felzenszwalb_Segmentation_10c_thresholded.jpg':'10 cents',\n",
        "    'Felzenszwalb_Segmentation_20c.jpg':'20 cents',\n",
        "    'Felzenszwalb_Segmentation_20c_O 1.png':'20 cents',\n",
        "    'Felzenszwalb_Segmentation_20c_R1.png' : '20 cents',\n",
        "    'Felzenszwalb_Segmentation_50c.jpg':'50 cents',\n",
        "    'Felzenszwalb_Segmentation_50c_O1.png':'50 cents',\n",
        "    'Felzenszwalb_Segmentation_50c_R1.png': '50 cents',\n",
        "    'Felzenszwalb_Segmentation_R1.jpg':'1 rand',\n",
        "    'Felzenszwalb_Segmentation_R1_O 1.png':'1 rand',\n",
        "    'Felzenszwalb_Segmentation_R1_R1.png': '1 rand',\n",
        "    'Felzenszwalb_Segmentation_R2.jpg':'2 rand',\n",
        "    'Felzenszwalb_Segmentation_R2_O1.png':'2 rand',\n",
        "    'Felzenszwalb_Segmentation_R2_R1.png':'2 rand',\n",
        "    'Felzenszwalb_Segmentation_R5.jpg':' 5 rand',\n",
        "    'Felzenszwalb_Segmentation_R5_O1.png': '5 rand',\n",
        "    'Felzenszwalb_Segmentation_R5_RA.png': '5 rand',\n",
        "    '10c_edge_segmented.jpg': '10 cents',\n",
        "    '10c_region_segmented.jpg': '10 cents',\n",
        "    '10c_thresholded.jpg': '10 cents',\n",
        "    'edges_10c.jpg':'10 cents',\n",
        "    'edges_10c_O 1.png': '10 cents',\n",
        "    'edges_10c_R1.png':'10 cents',\n",
        "    'edges_10c_edge_segmented.jpg':'10 cents',\n",
        "    'edges_10c_region_segmented.jpg':'10 cents',\n",
        "    'edges_20c.jpg':'20 cents',\n",
        "    'edges_20c_O 1.png':'20 cents',\n",
        "    'edges_20c_R1.png':'20 cents',\n",
        "    'edges_50c.jpg':'50 cents',\n",
        "    'edges_50c_O1.png':'50 cents',\n",
        "    'edges_50c_R1.png':'50 cents',\n",
        "    'edges_Felzenszwalb_Segmentation_10c.jpg':'10 cents',\n",
        "    'edges_Felzenszwalb_Segmentation_20c.jpg':'20 cents',\n",
        "    'edges_Felzenszwalb_Segmentation_50c.jpg':'50 cents',\n",
        "    'edges_Felzenszwalb_Segmentation_R1.jpg': '1 rand',\n",
        "    'edges_Felzenszwalb_Segmentation_R2.jpg': '2 rand',\n",
        "    'edges_Felzenszwalb_Segmentation_R2.jpg': '2 rand',\n",
        "    'edges_Felzenszwalb_Segmentation_R5.jpg':'5 rand',\n",
        "    'edges_R1.jpg':'1 rand',\n",
        "    'edges_R2.jpg':'2 rand',\n",
        "    'edges_R5.jpg':'5 rand',\n",
        "    'sharpened_10c.jpg':' 10 cents',\n",
        "    'sharpened_20c.jpg':' 20 cents',\n",
        "    'sharpened_50c.jpg':' 50 cents',\n",
        "    'sharpened_Felzenszwalb_Segmentation_10c.jpg':'10 cents',\n",
        "    'sharpened_Felzenszwalb_Segmentation_20c.jpg':'20 cents',\n",
        "    'sharpened_Felzenszwalb_Segmentation_50c.jpg':'50 cents',\n",
        "    'sharpened_Felzenszwalb_Segmentation_R1.jpg':'1 rand',\n",
        "    'sharpened_Felzenszwalb_Segmentation_R2.jpg':'2 rand',\n",
        "    'sharpened_Felzenszwalb_Segmentation_R5.jpg':'5 rand',\n",
        "    'sharpened_R1.jpg':'1 rand',\n",
        "    'sharpened_R2.jpg':'2 rand',\n",
        "    'sharpened_R5.jpg':'5 rand'\n",
        "\n",
        "}\n",
        "# Define a lookup table mapping color features to coin values\n",
        "lookup_table = {\n",
        "        # (131, 109, 73): '1 cent',\n",
        "        # (201, 164, 109): '2 cents',\n",
        "        # (202, 161, 112): '5 cents',\n",
        "        (184, 194, 218): 10,\n",
        "        (183, 197, 215): 20,\n",
        "        (186, 201, 217): 50,\n",
        "        (192, 192, 194): 1 ,\n",
        "        (201, 201, 202): 2 ,\n",
        "        (193, 202, 211): 5 ,\n",
        "        (168, 185, 197): 5\n",
        "    }\n",
        "# Iterate over the images in the folder\n",
        "for filename in os.listdir(dataset_dir):\n",
        "    # Check if the file has an image extension\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        # Load the segmented coins image\n",
        "        image_path = os.path.join(dataset_dir, filename)\n",
        "        segmented_coins = cv2.imread(image_path)\n",
        "\n",
        "        # Convert the segmented coins image to grayscale\n",
        "        gray_coins = cv2.cvtColor(segmented_coins, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Extract the features\n",
        "        # ...\n",
        "\n",
        "        # Color features\n",
        "        color_features = segmented_coins.reshape(-1, 3)  # Reshape the image to a 2D array\n",
        "        mean_color = color_features.mean(axis=0)  # Calculate the mean color values\n",
        "\n",
        "\n",
        "\n",
        "    # Find the closest color in the lookup table using Manhattan distance\n",
        "        closest_color = min(lookup_table, key=lambda x: np.sum(np.abs(x - mean_color)))\n",
        "\n",
        "    # Extract the value label from the lookup table\n",
        "        value_label = lookup_table[closest_color]\n",
        "\n",
        "    # Shape features\n",
        "        contours, _ = cv2.findContours(gray_coins, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if len(contours) > 0:\n",
        "          coin_contour = max(contours, key=cv2.contourArea)\n",
        "          perimeter = cv2.arcLength(coin_contour, True)\n",
        "        else:\n",
        "          perimeter = 0\n",
        "\n",
        "    # Texture features\n",
        "        glcm = greycomatrix(gray_coins, [1], [0], 256, symmetric=True, normed=True)\n",
        "        contrast = greycoprops(glcm, 'contrast')[0][0]\n",
        "        dissimilarity = greycoprops(glcm, 'dissimilarity')[0][0]\n",
        "        homogeneity = greycoprops(glcm, 'homogeneity')[0][0]\n",
        "        energy = greycoprops(glcm, 'energy')[0][0]\n",
        "        correlation = greycoprops(glcm, 'correlation')[0][0]\n",
        "        # Get the label for the image\n",
        "        label = label_mapping.get(filename)\n",
        "\n",
        "        # Append the features and labels\n",
        "        features = np.concatenate([mean_color, [perimeter, contrast, dissimilarity, homogeneity, energy, correlation,value_label]])\n",
        "\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "# Split the dataset\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = np.array(X_train)\n",
        "# Replace None with a placeholder value\n",
        "y_train = [label if label is not None else 'None' for label in y_train]\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the string labels to numeric values\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "#print(X_train)\n",
        "# # Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train2 = scaler.fit_transform(X_train)\n",
        "X_test2 = scaler.transform(X_test)\n",
        "\n",
        "# # Filter out None labels from y_train\n",
        "# y_train_filtered = [label for label in y_train if label is not None]\n",
        "\n",
        "# # Get unique labels\n",
        "# unique_labels = np.unique(y_train_filtered)\n",
        "\n",
        "# print(unique_labels)\n",
        "# # Train the classifier\n",
        "clf = SVC()\n",
        "clf = KNeighborsClassifier(n_neighbors=1)\n",
        "clf.fit(X_train, y_train_encoded)\n",
        "\n",
        "# # Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "# Decode the predicted labels\n",
        "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Replace the placeholder value with None\n",
        "y_pred_decoded = [label if label != 'None' else None for label in y_pred_decoded]\n",
        "\n",
        "# Sample test labels\n",
        "#y_test = ['10 cents', '5 rand', '2 rand', None, '5 rand', '1 rand', '10 cents', '2 rand', '5 rand']\n",
        "\n",
        "# Exclude None values from y_test and y_pred\n",
        "print(y_pred)\n",
        "y_test_filtered = [label for label in y_test if label is not None]\n",
        "y_pred_filtered = [label for label in y_pred_decoded if label is not None]\n",
        "print(y_test_filtered)\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_filtered, y_pred_filtered)\n",
        "print('Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "ErDQf0NPZYdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test_filtered, y_pred_filtered)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_filtered, y_pred_filtered, average='weighted')\n",
        "print('Precision:', precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_filtered, y_pred_filtered, average='weighted')\n",
        "print('Recall:', recall)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test_filtered, y_pred_filtered, average='weighted')\n",
        "print('F1-score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8_rBLsKlbRF",
        "outputId": "71017ca0-1176-4e4d-cdca-a62bf8c819a3"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.625\n",
            "Precision: 0.68125\n",
            "Recall: 0.625\n",
            "F1-score: 0.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test_filtered)\n",
        "print(y_pred_filtered)\n",
        "print(y_pred)\n",
        "print(y_test)\n",
        "#print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD6JL3JUkXn0",
        "outputId": "43800030-3b1c-4c9f-d8ab-9a9b2bc3bebc"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2 rand', '50 cents', '5 rand', '20 cents', '50 cents', '1 rand', '5 rand', '1 rand', '2 rand', '10 cents', '50 cents', '10 cents', '10 cents', '1 rand', '50 cents', '10 cents']\n",
            "['10 cents', '50 cents', '5 rand', '20 cents', '2 rand', '1 rand', '5 rand', ' 10 cents', '10 cents', '10 cents', '50 cents', '10 cents', '20 cents', '1 rand', '1 rand', '10 cents']\n",
            "[5 9 8 7 6 4 8 0 5 5 9 5 7 4 4 5]\n",
            "['2 rand', '50 cents', '5 rand', '20 cents', '50 cents', '1 rand', '5 rand', '1 rand', '2 rand', '10 cents', '50 cents', '10 cents', '10 cents', '1 rand', '50 cents', '10 cents']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create an instance of the classifier\n",
        "clf2 = SVC()\n",
        "\n",
        "# Train the classifier\n",
        "clf2.fit(X_train, y_train_encoded)\n",
        "\n",
        "# # Predict on the test set\n",
        "y_pred2 = clf2.predict(X_test)\n",
        "# Decode the predicted labels\n",
        "y_pred_decoded2 = label_encoder.inverse_transform(y_pred2)\n",
        "\n",
        "# Replace the placeholder value with None\n",
        "y_pred_decoded2 = [label if label != 'None' else None for label in y_pred_decoded2]\n",
        "\n",
        "# Sample test labels\n",
        "#y_test = ['10 cents', '5 rand', '2 rand', None, '5 rand', '1 rand', '10 cents', '2 rand', '5 rand']\n",
        "\n",
        "# Exclude None values from y_test and y_pred\n",
        "print(y_pred2)\n",
        "y_test_filtered2 = [label for label in y_test if label is not None]\n",
        "y_pred_filtered2 = [label for label in y_pred_decoded2 if label is not None]\n",
        "print(y_test_filtered2)\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_filtered, y_pred_filtered)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8UoWvNHj9LT",
        "outputId": "077e61ef-be21-4642-9232-b8eecc4c60f8"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
            "['2 rand', '50 cents', '5 rand', '20 cents', '50 cents', '1 rand', '5 rand', '1 rand', '2 rand', '10 cents', '50 cents', '10 cents', '10 cents', '1 rand', '50 cents', '10 cents']\n",
            "Accuracy: 0.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Load and process your image\n",
        "image = cv2.imread('/content/drive/MyDrive/Dataset/10c_edge_segmented.jpg')\n",
        "# Perform any necessary operations on the image\n",
        "\n",
        "image2 = cv2.imread('/content/drive/MyDrive/Dataset/10c_region_segmented.jpg')\n",
        "image3 = cv2.imread('/content/drive/MyDrive/Dataset/10c_region_segmented.jpg')\n",
        "# Display the image using Matplotlib\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')  # Optional: Remove axis labels\n",
        "plt.show()\n",
        "plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')  # Optional: Remove axis labels\n",
        "plt.show()\n",
        "plt.imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')  # Optional: Remove axis labels\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oPhl9gskoD_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.segmentation import slic\n",
        "from skimage.segmentation import felzenszwalb\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Load the image\n",
        "image_path = '/content/drive/MyDrive/Dataset/10c.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Convert the image to RGB\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Cluster-based segmentation using SLIC\n",
        "segments_slic = slic(image_rgb, n_segments=100, compactness=10, sigma=1)\n",
        "\n",
        "# Graph-based segmentation using Felzenszwalb's algorithm\n",
        "segments_felzenszwalb = felzenszwalb(image_rgb, scale=100, sigma=0.5, min_size=50)\n",
        "\n",
        "# Semantic segmentation using pre-trained MobileNetV2 model\n",
        "# Load the pre-trained MobileNetV2 model\n",
        "model = MobileNetV2(weights='imagenet', include_top=False)\n",
        "input_shape = (224, 224)  # Specify the desired input shape\n",
        "\n",
        "# Resize the image to match the input shape of the model\n",
        "resized_image = cv2.resize(image_rgb, input_shape)\n",
        "\n",
        "# Preprocess the image for the MobileNetV2 model\n",
        "preprocessed_image = preprocess_input(resized_image)\n",
        "\n",
        "# Expand dimensions to create a batch of size 1\n",
        "input_image = np.expand_dims(preprocessed_image, axis=0)\n",
        "\n",
        "# Perform semantic segmentation using the MobileNetV2 model\n",
        "preds = model.predict(input_image)\n",
        "segmentation_map = tf.argmax(preds, axis=-1)[0]\n",
        "\n",
        "# Display the segmented images\n",
        "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
        "ax[0, 0].imshow(image_rgb)\n",
        "ax[0, 0].set_title('Original Image')\n",
        "\n",
        "ax[0, 1].imshow(mark_boundaries(image_rgb, segments_slic))\n",
        "ax[0, 1].set_title('SLIC Segmentation')\n",
        "\n",
        "ax[1, 0].imshow(mark_boundaries(image_rgb, segments_felzenszwalb))\n",
        "ax[1, 0].set_title('Felzenszwalb Segmentation')\n",
        "\n",
        "ax[1, 1].imshow(segmentation_map, cmap='jet')\n",
        "ax[1, 1].set_title('Semantic Segmentation')\n",
        "\n",
        "for a in ax.ravel():\n",
        "    a.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VbKix7uWpcSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.segmentation import felzenszwalb\n",
        "import os\n",
        "\n",
        "# Folder path containing the images\n",
        "folder_path = '/content/drive/MyDrive/Dataset/'\n",
        "\n",
        "# Get a list of all files in the folder\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Loop over each file in the folder\n",
        "for file_name in file_list:\n",
        "    # Check if the file is an image (you can add more file extensions if needed)\n",
        "    if file_name.endswith('.jpg') or file_name.endswith('.png'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Load the image\n",
        "        image = cv2.imread(file_path)\n",
        "\n",
        "        # Convert the image to RGB\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Perform Felzenszwalb's algorithm for graph-based segmentation\n",
        "        segments_felzenszwalb = felzenszwalb(image_rgb, scale=100, sigma=0.5, min_size=50)\n",
        "\n",
        "        # Create a mask for the Felzenszwalb segments\n",
        "        mask = np.zeros_like(image_rgb)\n",
        "\n",
        "        for segment_id in np.unique(segments_felzenszwalb):\n",
        "            mask[segments_felzenszwalb == segment_id] = image_rgb[segments_felzenszwalb == segment_id]\n",
        "\n",
        "        # Save the Felzenszwalb segmentation image\n",
        "        output_path = os.path.join(folder_path, f'Felzenszwalb_Segmentation_{file_name}')\n",
        "        cv2.imwrite(output_path, mask)\n",
        "\n",
        "        print(f'Felzenszwalb Segmentation image saved successfully for {file_name}.')\n"
      ],
      "metadata": {
        "id": "oW6qUS-vqRue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Define the folder path\n",
        "folder_path = '/content/drive/MyDrive/Dataset'\n",
        "\n",
        "# Get the list of image files in the folder\n",
        "image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Loop through each image file\n",
        "for file in image_files:\n",
        "    # Read the image\n",
        "    image_path = os.path.join(folder_path, file)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Apply sharpening filter\n",
        "    kernel_sharpening = np.array([[-1,-1,-1],\n",
        "                                  [-1, 9,-1],\n",
        "                                  [-1,-1,-1]])\n",
        "    sharpened_image = cv2.filter2D(image, -1, kernel_sharpening)\n",
        "\n",
        "    # Apply edge detection filter\n",
        "    edges = cv2.Canny(image, 100, 200)\n",
        "\n",
        "    # Save the filtered images\n",
        "    sharpened_image_path = os.path.join(folder_path, 'sharpened_' + file)\n",
        "    edges_path = os.path.join(folder_path, 'edges_' + file)\n",
        "    cv2.imwrite(sharpened_image_path, sharpened_image)\n",
        "    cv2.imwrite(edges_path, edges)\n"
      ],
      "metadata": {
        "id": "OjO5W487xLnN"
      },
      "execution_count": 118,
      "outputs": []
    }
  ]
}